{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "import foresight.model\n",
    "import foresight.data_functions as fx_df\n",
    "importlib.reload(foresight.model)\n",
    "importlib.reload(fx_df)\n",
    "import numpy as np\n",
    "\n",
    "import sklearn.preprocessing as skpp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.random.random(200)#[0]\n",
    "d2 = np.random.random(500)#[0]\n",
    "#print(data)\n",
    "\n",
    "in_, out_ = fx_df.series_to_supervised(data, n_in=4, n_out=1)\n",
    "\n",
    "#print(in_)\n",
    "#print(\"\\n\")\n",
    "#print(out_)\n",
    "\n",
    "idx = 2\n",
    "\n",
    "out_[idx] = np.array([25])\n",
    "#print(\"\\n\")\n",
    "#print(out_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "#scaler_ = skpp.MinMaxScaler((-1, 1))\n",
    "\n",
    "txr = fx_df.Data_Transformer(transform = 'LogDiff', remove_outliers = True)\n",
    "\n",
    "#    def __init__(    self, \n",
    "#                     transform=None,\n",
    "#                     remove_outliers=False,\n",
    "#                     scaler='MinMaxScaler')\n",
    "#def data_transformer(data,\n",
    "#                     transform=None,\n",
    "#                     remove_outliers=False,\n",
    "#                     scaler='MinMaxScaler'):\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "d1, scaler_ = txr(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "txr2 = fx_df.Data_Transformer(transform = 'LogDiff', remove_outliers = True, scaler = scaler_)\n",
    "d2a,_ = txr2(d2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.50581367 0.48464359 0.09488445 0.36113847 0.58265267 0.24960819\n",
      " 0.46478924 0.29168865 0.14370979 0.90173351]\n",
      "\n",
      "\n",
      "[[-0.02853641]\n",
      " [ 1.07997854]\n",
      " [ 1.07997854]\n",
      " [ 0.39023129]\n",
      " [-0.6754271 ]\n",
      " [ 0.50544354]\n",
      " [-0.36859343]\n",
      " [-0.56307109]\n",
      " [-0.04754586]\n",
      " [-0.04754586]]\n"
     ]
    }
   ],
   "source": [
    "print(d2[:10])\n",
    "print('\\n')\n",
    "print(d2a[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "dd1i, dd1o = fx_df.series_to_supervised(data = d1,\n",
    "                         n_in=20,\n",
    "                         n_out=1,\n",
    "                         dropnan=True,\n",
    "                         separate_output_series=True)\n",
    "\n",
    "dd2i, dd2o = fx_df.series_to_supervised(data = d2,\n",
    "                         n_in=20,\n",
    "                         n_out=1,\n",
    "                         dropnan=True,\n",
    "                         separate_output_series=True)\n",
    "\n",
    "dd1i = dd1i.reshape(\n",
    "            (dd1i.shape[0], 20, 1))\n",
    "dd1o = dd1o.reshape((-1, 1))\n",
    "__oldest_datum = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "179\n",
      "20\n",
      "[161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178\n",
      "   0   1]\n"
     ]
    }
   ],
   "source": [
    "dd2i = dd2i.reshape(\n",
    "            (dd2i.shape[0], 20, 1))[:20]\n",
    "dd2o = dd2o.reshape((-1, 1))\n",
    "\n",
    "num_samples = dd1i.shape[0]\n",
    "new_samples = dd2i.shape[0]\n",
    "\n",
    "#print (dd1i)\n",
    "\n",
    "print(num_samples)\n",
    "print(new_samples)\n",
    "\n",
    "\n",
    "if new_samples > num_samples:\n",
    "    dd3i = dd2i[-num_samples:]\n",
    "else:\n",
    "    indices = np.arange(__oldest_datum, new_samples + __oldest_datum) % num_samples\n",
    "    for i_src, i_tgt in enumerate(indices):\n",
    "        dd3i[i_tgt] = dd2i[i_src]\n",
    "    __oldest_datum += new_samples\n",
    "    print (indices)\n",
    "\n",
    "#print(dd3i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 354\n",
      "355 709\n",
      "710 1064\n",
      "1065 1419\n",
      "1420 1490\n"
     ]
    }
   ],
   "source": [
    "cur = 0\n",
    "tot = 1490\n",
    "rf = 355\n",
    "\n",
    "idx = range(0, tot, rf)\n",
    "for n in idx:\n",
    "    print(n, n+rf -1 if n + rf -1 <= tot else tot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1.     1.002  1.006  1.012  1.02   1.03   1.042  1.056  1.072  1.09\n",
      "  1.11   1.132  1.156  1.182  1.21   1.24   1.272  1.306  1.342  1.38\n",
      "  1.42   1.462  1.506  1.552  1.6    1.65   1.702  1.756  1.812  1.87\n",
      "  1.93   1.992  2.056  2.122  2.19   2.26   2.332  2.406  2.482  2.56\n",
      "  2.64   2.722  2.806  2.892  2.98   3.07   3.162  3.256  3.352  3.45\n",
      "  3.55   3.652  3.756  3.862  3.97   4.08   4.192  4.306  4.422  4.54\n",
      "  4.66   4.782  4.906  5.032  5.16   5.29   5.422  5.556  5.692  5.83\n",
      "  5.97   6.112  6.256  6.402  6.55   6.7    6.852  7.006  7.162  7.32\n",
      "  7.48   7.642  7.806  7.972  8.14   8.31   8.482  8.656  8.832  9.01\n",
      "  9.19   9.372  9.556  9.742  9.93  10.12  10.312 10.506 10.702 10.9\n",
      " 11.1  ] \n",
      "\n",
      " [ 1.     1.002  1.006  1.012  1.02   1.03   1.042  1.056  1.072  1.09\n",
      "  1.11   1.132  1.156  1.182  1.21   1.24   1.272  1.306  1.342  1.38\n",
      "  1.42   1.462  1.506  1.552  1.6    1.65   1.702  1.756  1.812  1.87\n",
      "  1.93   1.992  2.056  2.122  2.19   2.26   2.332  2.406  2.482  2.56\n",
      "  2.64   2.722  2.806  2.892  2.98   3.07   3.162  3.256  3.352  3.45\n",
      "  3.55   3.652  3.756  3.862  3.97   4.08   4.192  4.306  4.422  4.54\n",
      "  4.66   4.782  4.906  5.032  5.16   5.29   5.422  5.556  5.692  5.83\n",
      "  5.97   6.112  6.256  6.402  6.55   6.7    6.852  7.006  7.162  7.32\n",
      "  7.48   7.642  7.806  7.972  8.14   8.31   8.482  8.656  8.832  9.01\n",
      "  9.19   9.372  9.556  9.742  9.93  10.12  10.312 10.506 10.702 10.9\n",
      " 11.1  ]\n"
     ]
    }
   ],
   "source": [
    "my_data = np.arange(1.0,1.100,.001)\n",
    "#my_data2 = my_data.copy()\n",
    "for idx in range(my_data.shape[0]):\n",
    "#    print(idx, \"%.3f\" % my_data[idx], (idx**2 ) * 0.001, str(\"%.3f\" % (my_data[idx] + (idx**2) * .001)))\n",
    "    my_data2[idx] = my_data[idx] + idx**2 * .001\n",
    "txr1 = fx_df.Data_Transformer(transform = 'LogDiff', remove_outliers = False, scaler=None)\n",
    "d1, scaler_ = txr1(my_data2)\n",
    "in_, out_ = fx_df.series_to_supervised(d1, n_in=60, n_out=1)\n",
    "\n",
    "\n",
    "dhat = my_data2.copy()\n",
    "dhat[61:101] = np.multiply(my_data2[60:100], np.exp(out_).flatten())\n",
    "\n",
    "print (my_data2, '\\n\\n', dhat)\n",
    "#import pandas as pd\n",
    "\n",
    "#d = pd.DataFrame(my_data2, dhat)\n",
    "#print(d)\n",
    "\n",
    "#print(my_data)\n",
    "#print(len(my_data2), len(out_))\n",
    "#print(my_data2[60], my_data2[61], my_data2[61] - my_data2[60], out_[0], out_[0] + my_data2[60])\n",
    "\n",
    "#print(my_data2)\n",
    "#print(d1)\n",
    "#print(out_.flatten())\n",
    "#for i in range(out_.shape[0]):\n",
    "#    print('original: %.4f' % (my_data2[i+ 61] ), 'new: %.4f' % (out_[i] + my_data2[i + 60]))\n",
    "#print(d1[60] + my_data2[59], my_data2[60])\n",
    "#print(in_.shape, out_.shape, '\\n\\n', in_, '\\n\\n\\n', out_)\n",
    "#print (len(out_))\n",
    "#print(out_[0])\n",
    "#print(out_[0].reshape(-1,1))\n",
    "#print(my_data[61])\n",
    "o1 = txr1.Invert_Scaling(out_) if scaler_ is not None else out_\n",
    "o2 = np.exp(o1)\n",
    "#print(o1)\n",
    "#print(o2)\n",
    "\n",
    "x00 = np.array(range(61,100))\n",
    "x01 = np.log(x00)\n",
    "x02 = x01[1:] - x01[:-1]\n",
    "#print(x02[:10])\n",
    "#print(x00, x01, x01[1:] - x01[:-1])\n",
    "\n",
    "x03 = x02 + x01[:-1]\n",
    "#print(np.exp(x03[:10]))\n",
    "\n",
    "x0 = txr1.Invert_Scaling(out_) if scaler_ is not None else out_\n",
    "x1 = np.exp(x0)\n",
    "\n",
    "#print (61 * x1[0])\n",
    "#print (x0, x1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_51\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_81 (LSTM)               (None, 40, 20)            1760      \n",
      "_________________________________________________________________\n",
      "lstm_82 (LSTM)               (None, 40, 20)            3280      \n",
      "_________________________________________________________________\n",
      "lstm_83 (LSTM)               (None, 20)                3280      \n",
      "_________________________________________________________________\n",
      "dense_42 (Dense)             (None, 1)                 21        \n",
      "=================================================================\n",
      "Total params: 8,341\n",
      "Trainable params: 8,341\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "[(1, 80), (20, 80), (80,), (20, 80), (20, 80), (80,), (20, 80), (20, 80), (80,), (20, 1), (1,)]\n",
      "[0, 1]\n",
      "5\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.layers import LSTM, Bidirectional, Dense, TimeDistributed, Dropout, Input\n",
    "from tensorflow.keras.models import Sequential\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "model = Sequential()\n",
    "#model.add(Input(40,40,1))\n",
    "model.add(LSTM(20, return_sequences = True, input_shape=(40, 1)))\n",
    "model.add(LSTM(20, return_sequences = True))\n",
    "\n",
    "model.add(LSTM(20))\n",
    "model.add(Dense(1))\n",
    "model.compile(optimizer='adam', loss='mse')\n",
    "model.summary()\n",
    "\n",
    "weights = model.get_weights()\n",
    "var_shapes = []\n",
    "\n",
    "cur_pop = list(range(2))\n",
    "\n",
    "for layer_id, layer in enumerate(model.get_weights()):\n",
    "    var_shapes.append(layer.shape)\n",
    "\n",
    "def init_weights(var_shapes, num):\n",
    "    pop = []\n",
    "    for vec in range(num):\n",
    "        vec = []\n",
    "        for shape in var_shapes:\n",
    "            #print(shape)\n",
    "            vec.append(tf.keras.initializers.GlorotNormal()(shape))\n",
    "         #   print(weights)\n",
    "        #vec = weights\n",
    "        pop.append(vec)\n",
    "    return pop\n",
    "    \n",
    "    \n",
    "print (var_shapes)\n",
    "\n",
    "print(cur_pop)\n",
    "cur_pop = init_weights(var_shapes, 5)\n",
    "print(len(cur_pop))\n",
    "\n",
    "#print(type(weights), len(weights), weights[0].shape, weights[1].shape, weights[2].shape)\n",
    "#print(weights[0][0])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
