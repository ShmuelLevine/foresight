{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1 -- import necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import sklearn.preprocessing as skpp\n",
    "\n",
    "import dask.dataframe as dd\n",
    "\n",
    "import os # os.path\n",
    "import datetime\n",
    "\n",
    "%matplotlib inline\n",
    "from matplotlib import pyplot as plt\n",
    "from numpy import array\n",
    "from tensorflow.keras.activations import relu, softsign\n",
    "from tensorflow.keras.layers import LSTM, Bidirectional, Dense, TimeDistributed, Dropout\n",
    "from tensorflow.keras.models import Sequential\n",
    "import tensorflow as tf\n",
    "\n",
    "%load_ext tensorboard\n",
    "\n",
    "import foresight.backtesting\n",
    "import foresight.data_functions as fx_df\n",
    "import foresight.model\n",
    "import foresight.util as fxu\n",
    "\n",
    "importlib.reload(fx_df)\n",
    "importlib.reload(fxu)\n",
    "importlib.reload(foresight.model)\n",
    "importlib.reload(foresight.backtesting)\n",
    "\n",
    "from tensorflow.keras.mixed_precision import experimental as mixed_precision\n",
    "policy = tf.keras.mixed_precision.experimental.Policy('mixed_float16')\n",
    "mixed_precision.set_policy(policy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 Specify the path of the source data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# src = '/var/local/foresight/timeseries/EURGBP-2016-01.pp1.xz'\n",
    "src = \"/var/local/foresight/timeseries/EURGBP-2017-1-6.csv\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1.1 Setup model parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "Parameters"
    ]
   },
   "outputs": [],
   "source": [
    "scaler_type = \"MinMaxScaler\"  # [MinMaxScaler, None]\n",
    "sample_time = \"5T\"  # T=minutes\n",
    "seq_len = 12  # 1 hours\n",
    "n_vars = 1\n",
    "num_outs = 1  # number of future outputs to forecast\n",
    "Transform = \"LogDiff\"  # [Diff, LogDiff, None]\n",
    "model_name = '0001_6-LSTM_5minData_1h_dropoff'\n",
    "models_base_path = '/var/local/foresight/models/Keras_Models/'\n",
    "model_path = models_base_path + model_name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1.2 Setup training parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_batch_size = 64\n",
    "training_epochs = 5000\n",
    "training_dropoff = 0.01"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3 Prepare Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1 Import the data\n",
    "\n",
    "1. Load the data into a dataframe\n",
    "2. Specify the column names\n",
    "3. Convert the date field into the correct datetime64 object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_raw = fx_df.GetTickdataDataframe(src, date_format_string='%m/%d/%Y %H:%M:%S.%f')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 Clean up the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not (fxu.VarExists(sample_time)):\n",
    "    raise RuntimeError(\"'sample_time' must be defined\")\n",
    "\n",
    "data = fx_df.clean_data(\n",
    "    data_raw,\n",
    "    remove_duplicates=True,\n",
    "    sample_frequency=sample_time,\n",
    "    sample_type=\"nearest\",\n",
    "    remove_weekends=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.3 Create transformer object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_txr = fx_df.Data_Transformer(Transform, 2, scaler_type)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.4 Extract data as an np.ndarray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_arr = data[\"bid\"].to_numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4 Prepare Keras model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def BuildModel():\n",
    "    if not (fxu.VarExists(seq_len)):\n",
    "        raise RuntimeError(\"'seq_len' must be defined\")\n",
    "\n",
    "    if not (fxu.VarExists(n_vars)):\n",
    "        raise RuntimeError(\"'n_vars' must be defined\")\n",
    "    \n",
    "    # TODO: fix this somehow\n",
    "    output_columns = [0]\n",
    "\n",
    "    Activation_Function = \"tanh\"  # ['tanh', 'softsign', 'relu', 'elu', 'LeakyReLU']\n",
    "\n",
    "    _metrics = [tf.keras.metrics.MeanAbsoluteError(name='mae'),\n",
    "                tf.keras.metrics.MeanAbsolutePercentageError(name='mape'), \n",
    "                tf.keras.metrics.MeanSquaredError(name='mse'), \n",
    "#                tf.keras.metrics.RootMeanSquaredError(name='rmse'), \n",
    "#                tf.keras.metrics.LogCoshError(name='logcosh'), \n",
    "#                tf.keras.metrics.MeanSquaredLogarithmicError(name='msle')\n",
    "               ]\n",
    "    \n",
    "    LSTM_model = Sequential()\n",
    "\n",
    "#    LSTM_model.add(LSTM(100, activation=Activation_Function, return_sequences=True, input_shape=(seq_len, n_vars), dropout=training_dropoff))\n",
    "    LSTM_model.add(LSTM(100, activation=Activation_Function, return_sequences=True, input_shape=(seq_len, n_vars), dropout=0))\n",
    "    LSTM_model.add(LSTM(100, activation=Activation_Function, return_sequences=True, dropout=training_dropoff))\n",
    "    LSTM_model.add(LSTM(100, activation=Activation_Function, return_sequences=True, dropout=training_dropoff))\n",
    "    LSTM_model.add(LSTM(100, activation=Activation_Function, return_sequences=True, dropout=training_dropoff))\n",
    "    LSTM_model.add(LSTM(100, activation=Activation_Function, return_sequences=True, dropout=training_dropoff))\n",
    "    LSTM_model.add(LSTM(100, activation=Activation_Function, return_sequences=False, dropout=training_dropoff))\n",
    "    LSTM_model.add(Dropout(training_dropoff))\n",
    "    LSTM_model.add(Dense(len(output_columns)))\n",
    "    # model.compile(loss= 'mae' , optimizer= 'nadam' )\n",
    "    LSTM_model.compile(loss= 'mae' , optimizer= 'adam', metrics = _metrics ) # 'adam'\n",
    "    # model.build()\n",
    "    print(LSTM_model.summary())\n",
    "    \n",
    "    return LSTM_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5 Create foresight.Model object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fx_model = foresight.model.Model(\n",
    "    model=BuildModel(),\n",
    "    data=data_arr,\n",
    "    data_freq=pd.Timedelta(sample_time),\n",
    "    seq_len=seq_len,\n",
    "    scaler=None,\n",
    "    forecast_horizon=1,\n",
    "    data_transform=data_txr,\n",
    "    stationary_transform=\"LogDiff\",\n",
    "    max_training_data_factor=1.5,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6 Fit timeseries Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.1 Setup callbacks\n",
    "\n",
    "Callbacks are used here for \n",
    "\n",
    "- saving checkpoint info to disk to allow resuming the training of a model if it becomes interrupted\n",
    "- saving tensorboard log information for visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.1.1 Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checkpoint parameters\n",
    "checkpoint_file = model_path + '/checkpoints/cp.ckpt'\n",
    "checkpoint_dir = os.path.dirname(checkpoint_file)\n",
    "cp_freq_in_epochs = 10\n",
    "\n",
    "# Tensorboard Parameters\n",
    "tb_path = model_path + '/logs'\n",
    "logdir = os.path.join(tb_path, datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.1.2 Create Checkpoint Callback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cp_approx_batches_per_epoch = (data_arr.shape[0] - seq_len)/training_batch_size\n",
    "cp_save_freq = int(cp_approx_batches_per_epoch * cp_freq_in_epochs)\n",
    "\n",
    "cp_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath = checkpoint_file,\n",
    "    save_weights_only=True,\n",
    "    save_freq=cp_save_freq,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.1.3 Create Tensorboard Callback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tb_callback = tf.keras.callbacks.TensorBoard(log_dir=logdir, histogram_freq=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.2 Setup model directory and load checkpoint data, if available"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(checkpoint_dir):\n",
    "    from pathlib import Path\n",
    "    Path(checkpoint_dir).mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "if os.path.isfile(checkpoint_file + '.index'):\n",
    "    fx_model._model.load_weights(checkpoint_file)\n",
    "    print('Loaded saved weights from checkpoint file')\n",
    "else:\n",
    "    fx_model._model.save_weights(checkpoint_file)\n",
    "    print('Initialized new checkpoint file')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.3 Fit the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.3.1 Start tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%tensorboard --logdir var/local/foresight/models/Keras_Models/0001_6-LSTM_5minData_3h/logs\n",
    "%tensorboard --logdir $tb_path --bind_all\n",
    "#from tensorboard import notebook\n",
    "#notebook.list()\n",
    "#notebook.display(port=6006)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = fx_model.Fit(\n",
    "    batch_size=training_batch_size,\n",
    "    epochs=training_epochs,\n",
    "    train_frac=5 / 5,\n",
    "    valid_frac=0 / 3,\n",
    "    verbose=1,\n",
    "    validate_model=False,\n",
    "    print_test_stat=False,\n",
    "    callbacks=[cp_callback, tb_callback],\n",
    "#    callbacks=[cp_callback],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fx_model._model.save(models_path + model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6 Backtest the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(foresight.backtesting)\n",
    "importlib.reload(fx_df)\n",
    "print(type(fx_model))\n",
    "backtester = foresight.backtesting.Backtester(\n",
    "    model=fx_model,\n",
    "    retraining_freq=pd.Timedelta(\"1W\"),\n",
    "    trading_rules={\n",
    "        \"trade_size\": 1_000,\n",
    "        \"stop_loss\": 0.00025,\n",
    "        \"take_profit\": 0.00025,\n",
    "        \"min_change\": 0.00005,\n",
    "        \"leverage\": 1,\n",
    "    },\n",
    "    initial_money=1_000,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bt_src = \"/var/local/foresight/timeseries/EURGBP-2017-7-13.csv\"\n",
    "forecast_data = fx_df.GetTickdataDataframe(bt_src, date_format_string='%m/%d/%Y %H:%M:%S.%f')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "backtester.Backtest(forecast_data, initial_retraining = 0, retrain_epochs = 25, retrain_verbose = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "toc-autonumbering": false,
  "toc-showmarkdowntxt": true
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
